model:
  base_learning_rate: 4.0e-05
  target: src.model_mesh.MVRecon
  params:
    init_ckpt: logs/instant-meshpollen-base_train/checkpoints/last.ckpt
    input_size: 320
    render_size: 512  # base model uses lower output resolution

    lrm_generator_config:
      target: src.models.lrm_mesh.InstantMesh
      params:
        encoder_feat_dim: 768
        encoder_freeze: false
        encoder_model_name: facebook/dino-vitb16
        transformer_dim: 1024         # base model uses 1024
        transformer_layers: 12        # base model uses 12
        transformer_heads: 64         # not specified, but likely matches your config
        triplane_low_res: 32          # base model uses 64
        triplane_high_res: 64         # base model uses 64
        triplane_dim: 40              # base model uses 40
        rendering_samples_per_ray: 20 # base model uses 96
        grid_res: 16                 # base model uses 128
        grid_scale: 2.1               # not specified, but can keep as is

data:
  target: src.data.objaverse.DataModuleFromConfig
  params:
    batch_size: 1
    num_workers: 1
    train:
      target: src.data.objaverse.PollenMultiObjectDataset
      params:
        root_dir: "pollen/pollen_train"
        input_view_num: 6
        target_view_num: 4
        total_view_n: 32
        fov: 50
        camera_rotation: True
    validation:
      target: src.data.objaverse.PollenMultiObjectDataset
      params:
        root_dir: "pollen/pollen_val"
        input_view_num: 4
        target_view_num: 2
        total_view_n: 32
        fov: 50
        camera_rotation: False

lightning:
  modelcheckpoint:
    params:
      every_n_train_steps: 2000
      save_top_k: -1
      save_last: true
  callbacks: {}

  trainer:
    benchmark: true
    max_epochs: -1
    val_check_interval: 1000
    num_sanity_val_steps: 0
    accumulate_grad_batches: 2
    check_val_every_n_epoch: 4
